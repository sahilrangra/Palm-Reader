# ğŸ“Œ Ollama LLaVA-based Palmistry AI

This project uses **Ollama's LLaVA (Large Language and Vision Assistant)** model to analyze palm images based on **Hindu palmistry** and generate horoscopes. ğŸ–ğŸ”®

## ğŸ“œ Features
- ğŸ–¼ **Image-based analysis** using Hindu palmistry principles
- ğŸ” **LLaVA model** for vision-language understanding
- ğŸ“ **Generates horoscopes** based on uploaded hand images
- ğŸš€ **Easy to use** with Python and Ollama

---
## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Install Ollama
First, install Ollama from the official site:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2ï¸âƒ£ Install Required Python Libraries
Ensure you have Python installed, then install dependencies:
```bash
pip install ollama
```

### 3ï¸âƒ£ Pull the LLaVA Model
Download the LLaVA model for image-based AI processing:
```bash
ollama pull llava
```

---
## ğŸš€ Usage

### Run the Script
Save your hand image as **`hand.jpeg`** and execute the script:
```bash
python palmistry_ai.py
```

### ğŸ–¥ Python Script (`palmistry_ai.py`)
```python
import base64
import ollama

def encode_image(image_path):
    """ Convert image to base64 format for AI processing """
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode("utf-8")

def generate_horoscope(image_path):
    """ Send encoded image to Ollama for palmistry-based horoscope """
    image_base64 = encode_image(image_path)

    response = ollama.chat(
        model="llava",
        messages=[
            {"role": "user", "content": "Analyze the following hand image based on Hindu palmistry and provide a horoscope."},
            {"role": "user", "images": [image_base64]}
        ],
    )
    
    return response['message']['content']

image_path = "hand.jpeg"
horoscope = generate_horoscope(image_path)

print("\nGenerated Horoscope:\n", horoscope)
```

---
## ğŸ”¥ Example Output
```bash
Generated Horoscope:
You have a strong and well-defined fate line, which suggests a determined and ambitious personality. Your heart line indicates deep emotional connections...
```

---
## ğŸ›  Troubleshooting
- **Error: Model not found?** â†’ Run `ollama pull llava` to download the model.
- **Invalid Image Format?** â†’ Ensure the image is **JPEG** or **PNG**.
- **API Issues?** â†’ Check if the **Ollama service is running** (`ollama serve`).

---
## ğŸ“œ License
This project is licensed under the **MIT License**.

---
## ğŸ¤ Contributing
Pull requests and suggestions are welcome! Fork the repo and contribute. ğŸ˜Š

---
## ğŸ”— References
- [Ollama Official Documentation](https://ollama.com)
- [LLaVA Model Overview](https://github.com/haotian-liu/LLaVA)

